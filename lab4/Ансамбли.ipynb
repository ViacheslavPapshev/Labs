{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3085ec43-34bb-4afb-9515-517e0489db3e",
   "metadata": {},
   "source": [
    "## Ансамбли и полносвязные нейронные сети\n",
    "В этом ноутбуке вам нужно обучить модели на датасете классификации из предыдущего ноутбука и сравнить результаты. Вам будет предоставлен baseline, на основе которого вы будете доделывать предсказывающие модели. Оценка лабы будет зависеть от ROC-AUC на тестовых данных по следующим критериям:\n",
    "\\\n",
    "AUC - на тестовых данных\n",
    "- $AUC \\leq 0.76$ - 0 баллов\n",
    "- $0.76 < AUC \\leq 0.77$ - 2 балла\n",
    "- $0.77 < AUC \\leq 0.78$ - 4 балла\n",
    "- $0.78 < AUC \\leq 0.79$ - 6 баллов\n",
    "- $0.79 < AUC \\leq 0.80$ - 8 баллов\n",
    "- $AUC > 0.80$ - 10 баллов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec07e3a2-480a-4350-868e-02679ff2aada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import  GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, roc_curve, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "563ad31b-5c83-4366-819a-34dad4edecdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Creditability  Account_Balance  Duration_of_Credit_monthly  \\\n",
      "0              1                1                          18   \n",
      "1              1                1                           9   \n",
      "2              1                2                          12   \n",
      "3              1                1                          12   \n",
      "4              1                1                          12   \n",
      "\n",
      "   Payment_Status_of_Previous_Credit  Purpose  Credit_Amount  \\\n",
      "0                                  4        2           1049   \n",
      "1                                  4        0           2799   \n",
      "2                                  2        9            841   \n",
      "3                                  4        0           2122   \n",
      "4                                  4        0           2171   \n",
      "\n",
      "   Value_Savings_Stocks  Length_of_current_employment  Instalment_per_cent  \\\n",
      "0                     1                             2                    4   \n",
      "1                     1                             3                    2   \n",
      "2                     2                             4                    2   \n",
      "3                     1                             3                    3   \n",
      "4                     1                             3                    4   \n",
      "\n",
      "   Sex_Marital_Status  ...  Duration_in_Current_address  \\\n",
      "0                   2  ...                            4   \n",
      "1                   3  ...                            2   \n",
      "2                   2  ...                            4   \n",
      "3                   3  ...                            2   \n",
      "4                   3  ...                            4   \n",
      "\n",
      "   Most_valuable_available_asset  Age_years  Concurrent_Credits  \\\n",
      "0                              2         21                   3   \n",
      "1                              1         36                   3   \n",
      "2                              1         23                   3   \n",
      "3                              1         39                   3   \n",
      "4                              2         38                   1   \n",
      "\n",
      "   Type_of_apartment  No_of_Credits_at_this_Bank  Occupation  \\\n",
      "0                  1                           1           3   \n",
      "1                  1                           2           3   \n",
      "2                  1                           1           2   \n",
      "3                  1                           2           2   \n",
      "4                  2                           2           2   \n",
      "\n",
      "   No_of_dependents  Telephone  Foreign_Worker  \n",
      "0                 1          1               1  \n",
      "1                 2          1               1  \n",
      "2                 1          1               1  \n",
      "3                 2          1               2  \n",
      "4                 1          1               2  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('german.csv', sep=';')\n",
    "print(data.head())\n",
    "\n",
    "X = data.iloc[:, 1:].to_numpy()\n",
    "y = data.iloc[:, 0].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f93737ec-e5eb-4d72-8beb-5dba4d4c581f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train, bins=2, edgecolor='k')\n",
    "plt.xticks([0, 1])\n",
    "plt.xlabel('Class (0: Non-Creditworthy, 1: Creditworthy)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Classes in Training Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05645358",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "\n",
    "# Создание модели с взвешиванием классов\n",
    "#model = RandomForestClassifier(class_weight=dict(enumerate(class_weights)), n_estimators=100)\n",
    "\n",
    "#ensemble = [RandomForestClassifier(n_estimators=191, random_state=42, max_depth=829, min_samples_leaf=3, max_leaf_nodes=72, min_samples_split=8 ) for _ in range(10)]#class_weight=dict(enumerate(class_weights)),n_estimators=100, max_depth=50\n",
    "#for model in ensemble:\n",
    "    #sample_indices = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "    #X_subset, y_subset = X_resampled[sample_indices], y_resampled[sample_indices]\n",
    "    #model.fit(X_subset, y_subset)\n",
    "#predictions = np.array([model.predict(X_test) for model in ensemble])\n",
    "\n",
    "#ensemble_predictions = np.mean(predictions.T, axis=1)\n",
    "#ensemble_predictions=np.round(ensemble_predictions.reshape(200,1))\n",
    "\n",
    "\n",
    "#erf_roc_auc = roc_auc_score(y_test, ensemble_predictions)\n",
    "#erf_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "#erf_precision = precision_score(y_test, ensemble_predictions)\n",
    "#erf_recall = recall_score(y_test, ensemble_predictions)\n",
    "\n",
    "#print(\"eRandom Forest метрики:\")\n",
    "#print(f\"ROC AUC: {erf_roc_auc:.2f}\")\n",
    "#print(f\"Accuracy: {erf_accuracy:.2f}\")\n",
    "#print(f\"Precision: {erf_precision:.2f}\")\n",
    "#print(f\"Recall: {erf_recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "661a8a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.6706404862085087\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import pandas as pd\n",
    " \n",
    "# # Загрузка и подготовка данных\n",
    "# data = pd.read_csv('german.csv', sep=';')\n",
    "# X = data.iloc[:, 1:].values\n",
    "# y = data.iloc[:, 0].values\n",
    "\n",
    "# # Стандартизация признаков\n",
    "# scaler = StandardScaler()\n",
    "# X_train_std = scaler.fit_transform(X_train)\n",
    "# X_test_std = scaler.transform(X_test)\n",
    " \n",
    "# # Разделение на обучающий и тестовый наборы данных\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "\n",
    "# # parameters = {'max_depth': range(12,100), 'n_estimators': range(85, 110)}#'min_weight_fraction_leaf': range(0.0 , 0.35 , 0.05), , 'min_impurity_decrease': range(0.0 , 0.35 , 0.01), 'n_estimators': range(50, 100),  'max_leaf_nodes': range(6, 100), , 'min_samples_split': range(2, 200), 'min_samples_leaf': range(1, 200)\n",
    "# # #829\n",
    "\n",
    "# # rf_model= RandomizedSearchCV(rf_model, parameters, cv=5, scoring='roc_auc')\n",
    " \n",
    "# rf_model.fit(X_train_std, y_train)\n",
    " \n",
    " \n",
    "# # Прогноз на тестовых данных\n",
    "# y_pred = rf_model.predict(X_test_std)\n",
    " \n",
    "# # Вычисление метрики ROC AUC\n",
    "# roc_auc = roc_auc_score(y_test, y_pred)\n",
    "# print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5edbed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.6898083216456288\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.utils import resample\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import pandas as pd\n",
    " \n",
    "# # Загрузка и подготовка данных\n",
    "# data = pd.read_csv('german.csv', sep=';')\n",
    "# X = data.iloc[:, 1:].values\n",
    "# y = data.iloc[:, 0].values\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_std = scaler.fit_transform(X_train)\n",
    "# X_test_std = scaler.transform(X_test)\n",
    " \n",
    "# # Разделение на обучающий и тестовый наборы данных\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# # Объединение обучающего набора данных\n",
    "# train_data = pd.DataFrame(X_train)\n",
    "# train_data['target'] = y_train\n",
    " \n",
    "# # Разделение классов\n",
    "# class_0 = train_data[train_data.target == 0]\n",
    "# class_1 = train_data[train_data.target == 1]\n",
    " \n",
    "# # Upsampling класса 1 для достижения баланса\n",
    "# class_1_upsampled = resample(class_1, replace=True, n_samples=len(class_0), random_state=42)\n",
    " \n",
    "# # Объединение обновленных классов\n",
    "# upsampled_data = pd.concat([class_0, class_1_upsampled])\n",
    " \n",
    "# # Подготовка данных для обучения модели\n",
    "# X_train_upsampled = upsampled_data.iloc[:, :-1].values\n",
    "# y_train_upsampled = upsampled_data.iloc[:, -1].values\n",
    " \n",
    "# # Обучение модели\n",
    "# model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# model.fit(X_train_upsampled, y_train_upsampled)\n",
    " \n",
    "# # Прогноз на тестовых данных\n",
    "# y_pred = model.predict(X_test)\n",
    " \n",
    "# # Вычисление метрики ROC AUC\n",
    "# roc_auc = roc_auc_score(y_test, y_pred)\n",
    "# print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da55cb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.7006778868630201\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.utils import resample\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# # Загрузка и подготовка данных\n",
    "# data = pd.read_csv('german.csv', sep=';')\n",
    "# X = data.iloc[:, 1:].values\n",
    "# y = data.iloc[:, 0].values\n",
    " \n",
    "# # Разделение на обучающий и тестовый наборы данных\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    " \n",
    "# # Используем RandomUnderSampler для downsampling класса 0\n",
    "# rus = RandomUnderSampler(random_state=42)\n",
    "# X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
    " \n",
    "# # Обучение модели и подбор параметров с помощью GridSearchCV\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [None, 5, 10],\n",
    "#     'min_samples_split': [2, 5, 10]\n",
    "# }\n",
    " \n",
    "# model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# ensemble = [model for _ in range(10)]#class_weight=dict(enumerate(class_weights)),n_estimators=100, max_depth=50\n",
    "# for model in ensemble:\n",
    "#     sample_indices = np.random.choice(len(X_train_res), size=len(X_train_res), replace=True)\n",
    "#     X_subset, y_subset = X_train_res[sample_indices], y_train_res[sample_indices]\n",
    "#     grid_search = GridSearchCV(model, param_grid, scoring='roc_auc')\n",
    "#     grid_search.fit(X_subset, y_subset)\n",
    "# predictions = np.array([grid_search.best_estimator_.predict(X_test) for model in ensemble])\n",
    "\n",
    "# ensemble_predictions = np.mean(predictions.T, axis=1) - 0.1\n",
    "# ensemble_predictions=np.round(ensemble_predictions.reshape(200,1))\n",
    "\n",
    "# # # Лучшая модель после подбора параметров\n",
    "# # best_model = grid_search.best_estimator_\n",
    " \n",
    "# # # Прогноз на тестовых данных\n",
    "# # y_pred = best_model.predict(X_test)\n",
    " \n",
    "# # Вычисление метрики ROC AUC\n",
    "# roc_auc = roc_auc_score(y_test, ensemble_predictions)\n",
    "# print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a44578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest ROC AUC: 0.8149836372136512\n",
      "XGBoost ROC AUC: 0.7477793361383824\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    " \n",
    "# Загрузка и подготовка данных\n",
    "data = pd.read_csv('german.csv', sep=';')\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    " \n",
    "# Разделение на обучающий и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# Инженерия признаков с полиномиальными признаками (степень 2)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    " \n",
    "\n",
    "\n",
    " \n",
    "# Случайный лес\n",
    "param_grid_rf = {'n_estimators': [100, 200, 500]}\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5)\n",
    "grid_search_rf.fit(X_train_poly, y_train)\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    " \n",
    "# XGBoost\n",
    "param_grid_xgb = {'n_estimators': [100, 200, 500], 'max_depth': [3, 5, 7]}\n",
    "grid_search_xgb = GridSearchCV(XGBClassifier(), param_grid_xgb, cv=5)\n",
    "grid_search_xgb.fit(X_train_poly, y_train)\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    " \n",
    "# Применение SMOTE для перебалансировки классов\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_poly, y_train)\n",
    " \n",
    "# Обучение моделей на сбалансированных данных\n",
    "best_rf.fit(X_train_resampled, y_train_resampled)\n",
    "best_xgb.fit(X_train_resampled, y_train_resampled)\n",
    " \n",
    "# Прогноз на тестовых данных\n",
    "y_pred_rf = best_rf.predict_proba(X_test_poly)[:, 1]\n",
    "y_pred_xgb = best_xgb.predict_proba(X_test_poly)[:, 1]\n",
    " \n",
    "# Вычисление метрики ROC AUC\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "roc_auc_xgb = roc_auc_score(y_test, y_pred_xgb)\n",
    "\n",
    "\n",
    "print(\"Random Forest ROC AUC:\", roc_auc_rf)\n",
    "print(\"XGBoost ROC AUC:\", roc_auc_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31d84bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ROC AUC меньше 0.8\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.metrics import roc_auc_score\n",
    " \n",
    "# # Загрузка и подготовка данных\n",
    "# data = pd.read_csv('german.csv', sep=';')\n",
    "# X = data.iloc[:, 1:].values\n",
    "# y = data.iloc[:, 0].values\n",
    " \n",
    "# # Разделение на обучающий и тестовый наборы данных\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# # Применение SMOTE для перебалансировки классов\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    " \n",
    "# # Подбор гиперпараметров с помощью GridSearchCV\n",
    "# param_grid = {'n_estimators': [100, 200, 500], 'max_depth': [3, 5, 7]}\n",
    "# grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "# grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "# best_model = grid_search.best_estimator_\n",
    " \n",
    "# # Прогноз на тестовых данных\n",
    "# y_pred = best_model.predict_proba(X_test)[:, 1]\n",
    " \n",
    "# # Вычисление метрики ROC AUC\n",
    "# roc_auc = roc_auc_score(y_test, y_pred)\n",
    " \n",
    "# if roc_auc > 0.8:\n",
    "#     print(\"ROC AUC:\", roc_auc)\n",
    "# else:\n",
    "#     print(\"Метрика ROC AUC меньше 0.8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d636a0be",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m600\u001b[39m, \u001b[38;5;241m900\u001b[39m, \u001b[38;5;241m1000\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m20\u001b[39m]}\n\u001b[0;32m     28\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(GradientBoostingClassifier(), param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Прогноз на тестовых данных\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:532\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    531\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 532\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:610\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    603\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    604\u001b[0m             y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    605\u001b[0m             raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    606\u001b[0m             sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    607\u001b[0m         )\n\u001b[0;32m    609\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 610\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:245\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    242\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    244\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 245\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    248\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    249\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    250\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    258\u001b[0m )\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    " \n",
    "# Загрузка и подготовка данных\n",
    "data = pd.read_csv('german.csv', sep=';')\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    " \n",
    "# Разделение на обучающий и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Инженерия признаков с полиномиальными признаками (степень 2)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    " \n",
    " \n",
    "# Применение SMOTE для перебалансировки классов\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_poly, y_train)\n",
    " \n",
    "# Подбор гиперпараметров с помощью GridSearchCV\n",
    "param_grid = {'n_estimators': [100, 200, 500, 600, 900, 1000], 'max_depth': [3, 5, 7, 9, 12, 15, 20]}\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "best_model = grid_search.best_estimator_\n",
    " \n",
    "# Прогноз на тестовых данных\n",
    "y_pred = best_model.predict_proba(X_test_poly)[:, 1]\n",
    " \n",
    "# Вычисление метрики ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    " \n",
    "\n",
    "print(\"ROC AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4223cc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.7598176718092567\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    " \n",
    "# Загрузка и подготовка данных\n",
    "data = pd.read_csv('german.csv', sep=';')\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    " \n",
    "# Разделение на обучающий и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# Применение SMOTE для перебалансировки классов\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    " \n",
    "# Подбор гиперпараметров с помощью GridSearchCV\n",
    "param_grid = {'n_estimators': [100, 200, 500, 600, 1000], 'learning_rate': [0.1, 0.01, 0.001]}\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Прогноз на тестовых данных\n",
    "y_pred = best_model.predict_proba(X_test)[:, 1]\n",
    " \n",
    "# Вычисление метрики ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    " \n",
    "print(\"ROC AUC: Gradient boosting\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ad1b2d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m500\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.001\u001b[39m]}\n\u001b[0;32m     29\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(GradientBoostingClassifier(), param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Прогноз на тестовых данных\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:532\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    531\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 532\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:610\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    603\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    604\u001b[0m             y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    605\u001b[0m             raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    606\u001b[0m             sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    607\u001b[0m         )\n\u001b[0;32m    609\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 610\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:245\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    242\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    244\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 245\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    248\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    249\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    250\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    258\u001b[0m )\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    " \n",
    "# Загрузка и подготовка данных\n",
    "data = pd.read_csv('german.csv', sep=';')\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    " \n",
    "\n",
    " \n",
    "# Разделение на обучающий и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Инженерия признаков (пример)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_test = poly.transform(X_test)\n",
    " \n",
    "# Применение SMOTE для перебалансировки классов\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    " \n",
    "# Подбор гиперпараметров с помощью GridSearchCV\n",
    "param_grid = {'n_estimators': [100, 200, 500], 'learning_rate': [0.1, 0.01, 0.001]}\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "best_model = grid_search.best_estimator_\n",
    " \n",
    "# Прогноз на тестовых данных\n",
    "y_pred = best_model.predict_proba(X_test)[:, 1]\n",
    " \n",
    "# Вычисление метрики ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    " \n",
    "print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7fa56cc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m600\u001b[39m, \u001b[38;5;241m900\u001b[39m, \u001b[38;5;241m1000\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.01\u001b[39m]}\n\u001b[0;32m     27\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(GradientBoostingClassifier(), param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Прогноз на тестовых данных\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:532\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    531\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 532\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:610\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    603\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    604\u001b[0m             y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    605\u001b[0m             raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    606\u001b[0m             sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    607\u001b[0m         )\n\u001b[0;32m    609\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 610\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:245\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    242\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    244\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 245\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    248\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    249\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    250\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    258\u001b[0m )\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# Загрузка и подготовка данных\n",
    "data = pd.read_csv('german.csv', sep=';')\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    " \n",
    "# Разделение на обучающий и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    " \n",
    "# Применение SMOTE для перебалансировки классов в обучающем наборе\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    " \n",
    "# Подбор гиперпараметров с помощью GridSearchCV\n",
    "param_grid = {'n_estimators': [100, 200, 300, 500, 600, 900, 1000], 'learning_rate': [0.1, 0.01]}\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=3, scoring='roc_auc')\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "best_model = grid_search.best_estimator_\n",
    " \n",
    "# Прогноз на тестовых данных\n",
    "y_pred = best_model.predict_proba(X_test)[:, 1]\n",
    " \n",
    "# Вычисление и вывод метрики ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a69333e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.732468443197756\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    " \n",
    "# Загрузка и подготовка данных\n",
    "data = pd.read_csv('german.csv', sep=';')\n",
    " \n",
    "# Инженерия признаков\n",
    "# Примените необходимые преобразования и оцените оптимальные признаки для вашего случая\n",
    " \n",
    "# Выделение признаков и целевой переменной\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    " \n",
    "# Разделение на обучающий и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# Создание пайплайна для объединения перебалансировки, оверсэмплинга и классификации\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('mlp', MLPClassifier(random_state=42))\n",
    "])\n",
    " \n",
    "# Определение пространства параметров для подбора\n",
    "param_grid = {\n",
    "    'mlp__hidden_layer_sizes': [(50,), (100,), (100, 50), (50, 50)],\n",
    "    'mlp__activation': ['relu', 'tanh'],\n",
    "    'mlp__alpha': [0.0001, 0.001, 0.01],\n",
    "}\n",
    " \n",
    "# Подбор гиперпараметров с помощью GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    " \n",
    "# Прогноз на тестовых данных\n",
    "y_pred = best_model.predict_proba(X_test)[:, 1]\n",
    " \n",
    "# Вычисление и вывод метрики ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC AUC: MLP\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b74beea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(800, 0)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Масштабирование признаков\u001b[39;00m\n\u001b[0;32m     23\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m---> 24\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m X_test \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Применение SMOTE для перебалансировки классов в обучающем наборе\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\base.py:916\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    915\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:839\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 839\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:875\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \n\u001b[0;32m    845\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    874\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 875\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\sklearn\\utils\\validation.py:976\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    974\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m<\u001b[39m ensure_min_features:\n\u001b[1;32m--> 976\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    977\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m feature(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    978\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    979\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_features, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_features, context)\n\u001b[0;32m    980\u001b[0m         )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(800, 0)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    " \n",
    "# Загрузка и подготовка данных\n",
    "data = pd.read_csv('german.csv')\n",
    " \n",
    "# Примените необходимые преобразования и оцените оптимальные признаки для вашего случая\n",
    "# Здесь предполагается, что данные уже подготовлены и масштабированы\n",
    " \n",
    "# Выделение признаков и целевой переменной\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    " \n",
    "# Разделение на обучающий и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# Масштабирование признаков\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    " \n",
    "# Применение SMOTE для перебалансировки классов в обучающем наборе\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    " \n",
    "# Подбор оптимальных параметров с помощью GridSearchCV\n",
    "parameters = {'hidden_layer_sizes': [(100, 50), (50, 50, 50), (100, 100, 100)],\n",
    "              'activation': ['logistic', 'relu'],\n",
    "              'alpha': [0.0001, 0.001, 0.01]}\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(mlp, parameters, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    " \n",
    "# Лучшая модель после подбора параметров\n",
    "best_mlp = grid_search.best_estimator_\n",
    " \n",
    "# Прогноз на тестовых данных\n",
    "y_pred = best_mlp.predict_proba(X_test)[:, 1]\n",
    " \n",
    "# Вычисление и вывод метрики ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "87145866",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Creditability'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 18\u001b[0m\n\u001b[0;32m     12\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Примените необходимые преобразования и оцените оптимальные признаки для вашего случая\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Здесь предполагается, что данные уже подготовлены и масштабированы\u001b[39;00m\n\u001b[0;32m     16\u001b[0m  \n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Выделение признаков и целевой переменной\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCreditability\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     19\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreditability\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Разделение на обучающий и тестовый наборы данных\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\frame.py:5347\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5201\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5208\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5211\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5212\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5345\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5353\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5354\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6992\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6993\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6994\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Creditability'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Загрузка и подготовка данных\n",
    "data = pd.read_csv('german.csv')\n",
    "\n",
    "data.head()\n",
    " \n",
    "# Примените необходимые преобразования и оцените оптимальные признаки для вашего случая\n",
    "# Здесь предполагается, что данные уже подготовлены и масштабированы\n",
    " \n",
    "# Выделение признаков и целевой переменной\n",
    "X = data.drop(columns=['Creditability']).values\n",
    "y = data['Creditability'].values\n",
    " \n",
    "# Разделение на обучающий и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# Масштабирование признаков\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    " \n",
    "# Применение SMOTE для перебалансировки классов в обучающем наборе\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    " \n",
    "# Подбор оптимальных параметров с помощью GridSearchCV\n",
    "parameters = {'hidden_layer_sizes': [(100, 50), (50, 50, 50), (100, 100, 100)],\n",
    "              'activation': ['logistic', 'relu'],\n",
    "              'alpha': [0.0001, 0.001, 0.01]}\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(mlp, parameters, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    " \n",
    "# Лучшая модель после подбора параметров\n",
    "best_mlp = grid_search.best_estimator_\n",
    " \n",
    "# Прогноз на тестовых данных\n",
    "y_pred = best_mlp.predict_proba(X_test)[:, 1]\n",
    " \n",
    "# Вычисление и вывод метрики ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "if roc_auc > 0.8:\n",
    "    print(\"Метрика ROC AUC больше 0.8:\", roc_auc)\n",
    "else:\n",
    "    print(\"Метрика ROC AUC меньше или равна 0.8:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1cf8d00-92a3-4b62-bca4-d854b72574d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest метрики:\n",
      "ROC AUC: 0.74\n",
      "Accuracy: 0.78\n",
      "Precision: 0.84\n",
      "Recall: 0.84\n",
      "\n",
      "Gradient Boosting метрики:\n",
      "ROC AUC: 0.72\n",
      "Accuracy: 0.74\n",
      "Precision: 0.84\n",
      "Recall: 0.77\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "\n",
    "# Применение увеличения выборки к данным\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# Обучение Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=10, random_state=42, max_depth=829, min_samples_leaf=3, max_leaf_nodes=72, min_samples_split=8)#md - 6 # {'max_depth': 50, 'n_estimators': 100}\n",
    "\n",
    "\n",
    "parameters = {'max_depth': range(12,100), 'n_estimators': range(85, 110)}#'min_weight_fraction_leaf': range(0.0 , 0.35 , 0.05), , 'min_impurity_decrease': range(0.0 , 0.35 , 0.01), 'n_estimators': range(50, 100),  'max_leaf_nodes': range(6, 100), , 'min_samples_split': range(2, 200), 'min_samples_leaf': range(1, 200)\n",
    "#829\n",
    "\n",
    "rf_model= RandomizedSearchCV(rf_model, parameters, cv=5, scoring='roc_auc')\n",
    "rf_model.fit(X_resampled, y_resampled)   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Прогноз на тестовых данных\n",
    "rf_pred = rf_model.best_estimator_.predict(X_test)\n",
    "\n",
    "# Расчет метрик для Random Forest\n",
    "rf_roc_auc = roc_auc_score(y_test, rf_pred)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "rf_precision = precision_score(y_test, rf_pred)\n",
    "rf_recall = recall_score(y_test, rf_pred)\n",
    "\n",
    "print(\"Random Forest метрики:\")\n",
    "print(f\"ROC AUC: {rf_roc_auc:.2f}\")\n",
    "print(f\"Accuracy: {rf_accuracy:.2f}\")\n",
    "print(f\"Precision: {rf_precision:.2f}\")\n",
    "print(f\"Recall: {rf_recall:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Обучение Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(n_estimators=40, random_state=42)\n",
    "\n",
    "parameters = {'min_samples_split': range(4,10), 'min_samples_leaf': range(1,11)} #'learning_rate': range(0 , 0.35 , 0.05), , 'min_samples_split': range(4,100), 'min_samples_leaf': range(1,50) 'n_estimators': range(100,1000)\n",
    "gb_model = RandomizedSearchCV(gb_model, parameters, cv=10, scoring='roc_auc')\n",
    "gb_model.fit(X_resampled, y_resampled)\n",
    "#print(gb_model.best_params_)\n",
    "\n",
    "# Прогноз на тестовых данных\n",
    "gb_pred = gb_model.best_estimator_.predict(X_test)\n",
    "\n",
    "# Расчет метрик для Gradient Boosting\n",
    "gb_roc_auc = roc_auc_score(y_test, gb_pred)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "gb_precision = precision_score(y_test, gb_pred)\n",
    "gb_recall = recall_score(y_test, gb_pred)\n",
    "\n",
    "print(\"\\nGradient Boosting метрики:\")\n",
    "print(f\"ROC AUC: {gb_roc_auc:.2f}\")\n",
    "print(f\"Accuracy: {gb_accuracy:.2f}\")\n",
    "print(f\"Precision: {gb_precision:.2f}\")\n",
    "print(f\"Recall: {gb_recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae1e040c-ddd0-4952-9dcb-58c1226da40a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP (Neural Network) метрики:\n",
      "ROC AUC: 0.57\n",
      "Accuracy: 0.48\n",
      "Precision: 0.80\n",
      "Recall: 0.33\n"
     ]
    }
   ],
   "source": [
    "# Обучение MLP (Multi-Layer Perceptron) нейронной сети\n",
    "ros = RandomOverSampler()\n",
    "\n",
    "# Применение увеличения выборки к данным\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(30,), max_iter=500, random_state=42)\n",
    "\n",
    "mlp_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "\n",
    "# Прогноз на тестовых данных\n",
    "mlp_pred = mlp_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "mlp_roc_auc = roc_auc_score(y_test, mlp_pred)\n",
    "mlp_accuracy = accuracy_score(y_test, mlp_pred)\n",
    "mlp_precision = precision_score(y_test, mlp_pred)\n",
    "mlp_recall = recall_score(y_test, mlp_pred)\n",
    "\n",
    "print(\"\\nMLP (Neural Network) метрики:\")\n",
    "print(f\"ROC AUC: {mlp_roc_auc:.2f}\")\n",
    "print(f\"Accuracy: {mlp_accuracy:.2f}\")\n",
    "print(f\"Precision: {mlp_precision:.2f}\")\n",
    "print(f\"Recall: {mlp_recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'hidden_layer_sizes': (range(30, 35),), 'max_iter': range(180,210), 'solver':['lbfgs', 'sgd', 'adam']}\n",
    "# mlp_model = RandomizedSearchCV(mlp_model, parameters, cv=5, scoring='roc_auc')\n",
    "\n",
    "# ensemble1 = [MLPClassifier(hidden_layer_sizes=(30,), max_iter=500, random_state=42) for _ in range(100)]#class_weight=dict(enumerate(class_weights)),n_estimators=100, max_depth=50\n",
    "# ensamble2 = [RandomForestClassifier(n_estimators=191, random_state=42, max_depth=829, min_samples_leaf=3, max_leaf_nodes=72, min_samples_split=8) for _ in range(100)]\n",
    "# ensamble3 = [GradientBoostingClassifier(n_estimators=990, random_state=42) for _ in range(100)] \n",
    "# bg_e=[]\n",
    "# for model1, model2, model3 in zip(ensemble1, ensamble2, ensamble3):\n",
    "#     sample_indices = np.random.choice(len(X_resampled), size=len(X_resampled), replace=True)\n",
    "#     X_subset, y_subset = X_resampled[sample_indices], y_resampled[sample_indices]\n",
    "#     bg1 = BaggingClassifier(model1, max_samples=0.4, max_features=10)\n",
    "#     bg2 = BaggingClassifier(model1, max_samples=0.4, max_features=10)\n",
    "#     bg3 = BaggingClassifier(model1, max_samples=0.4, max_features=10)\n",
    "#     bg1.fit(X_subset, y_subset)\n",
    "#     bg2.fit(X_subset, y_subset)\n",
    "#     bg3.fit(X_subset, y_subset)\n",
    "#     bg = np.mean((bg1.predict(X_test) + bg2.predict(X_test) + bg3.predict(X_test))/3)\n",
    "#     bg_e.append(bg)\n",
    "# bgo= np.mean(bg_e, axis=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "# predictions1 = pd.DataFrame([model.predict(X_test) for model in ensemble1])\n",
    "# predictions2 = pd.DataFrame([model.predict(X_test) for model in ensemble1])\n",
    "# predictions3 = pd.DataFrame([model.predict(X_test) for model in ensemble1])\n",
    "\n",
    "# ensemble_predictions = predictions.rank(axis=1, method=\"first\")\n",
    "# ensemble_predictions1 = np.round(np.mean(predictions1.to_numpy(), axis=0)).T\n",
    "# ensemble_predictions2 = np.round(np.mean(predictions2.to_numpy(), axis=0)).T\n",
    "# ensemble_predictions3 = np.round(np.mean(predictions3.to_numpy(), axis=0)).T\n",
    "# end = np.round((ensemble_predictions1 + ensemble_predictions2 + ensemble_predictions3)/3).T\n",
    "\n",
    "# print(end)\n",
    "# ensemble_predictions=np.round(ensemble_predictions.reshape(200,1))\n",
    "\n",
    "\n",
    "# Расчет метрик для MLP нейронной сети\n",
    "# mlp_roc_auc = roc_auc_score(y_test, mlp_pred)\n",
    "# mlp_accuracy = accuracy_score(y_test, mlp_pred)\n",
    "# mlp_precision = precision_score(y_test, mlp_pred)\n",
    "# mlp_recall = recall_score(y_test, mlp_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d6eb00-77fd-40dc-a3c5-35c1fe0200c0",
   "metadata": {},
   "source": [
    "## Экспериментируйте\n",
    "Для получения лучшего качества придется поэкспериментировать. Подсказка: попробуйте оптимизировать гиперпараметры модели"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
